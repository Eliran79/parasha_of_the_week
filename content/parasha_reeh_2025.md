---
title: "פרשת ראה: נביא השקר הדיגיטלי - כשמודלי שפה נותנים אותות ומופתים משכנעים אבל מוליכים שולל"
parasha: "ראה"
date: "2025-08-15"
tags: ["בינה_מלאכותית", "הזיות_מודלים", "נביא_שקר", "Claude_Code", "Test_Mode"]
emoji: "🔮"
excerpt: "פרשת ראה מזהירה מנביא שנותן אותות ומופתים אבל מוליך שולל. השבוע גיליתי שמודלי שפה עושים בדיוק את זה - ובניתי כלי הגנה שמיישם את העקרונות התורניים"
author: "אלירן סבג"
year: 2025
---

# פרשת ראה: נביא השקר הדיגיטלי - כשמודלי שפה נותנים אותות ומופתים משכנעים אבל מוליכים שולל

## 🔮 האזהרה הנבואית: כשהאמת לא נמדדת בתוצאות

פרשת ראה פותחת עם אחת האזהרות החדות ביותר בתורה:

> **"כִּֽי־יָק֤וּם בְּקִרְבְּךָ֙ נָבִ֔יא א֖וֹ חֹלֵ֣ם חֲל֑וֹם וְנָתַ֥ן אֵלֶ֛יךָ א֖וֹת א֥וֹ מוֹפֵֽת׃ וּבָא֙ הָא֣וֹת וְהַמּוֹפֵ֔ת אֲשֶׁר־דִּבֶּ֥ר אֵלֶ֖יךָ... לֹ֣א תִשְׁמַ֗ע אֶל־דִּבְרֵי֙ הַנָּבִ֣יא הַה֔וּא"** (דברים יג:ב-ד)

**הפרדוקס המרכזי**: גם כשהנביא השקר נותן **"אות ומופת"** שמתגשמים - **עדיין אסור להאמין לו**.

זה רעיון מהפכני: האמת לא נמדדת רק בתוצאות המיידיות. גם דבר שנראה "עובד" יכול להוביל לדרך הלא נכונה.

השבוע, בעבודה עם מודלי AI, גיליתי שהאזהרה הזו רלוונטית יותר מאי פעם.

## 🧠 למה מודלי שפה "מזיינים" - ההסבר הטכני

### הבעיה היסודית: אימון "לרצות" במקום "להיות נכון"

מודלי שפה גדולים אומנו בצורה שגורמת להם לייצר תוכן ש**נראה מהימן ושימושי**, לא בהכרח **נכון**.

**שלושת הגורמים המרכזיים להזיות:**

#### 1️⃣ **זיכרון רחוק מול קרוב** - התפלגות הידע לא אחידה
המודל "זוכר" טוב יותר דברים שהופיעו הרבה פעמים באימון, ופחות טוב דברים נדירים. כשהוא לא בטוח, הוא ממציא פרטים שנראים הגיוניים.

#### 2️⃣ **התפלגות הטוקנים** - אחת הבעיות העמוקות ביותר
המודל חושב ב"טוקנים" (יחידות טקסט), לא במושגים. הוא יכול לייצר רצף טוקנים שנראה כמו הפנייה לספר אמיתי, אבל בעצם זה רק צירוף מקרי של טוקנים נפוצים.

#### 3️⃣ **אימון RLHF** - "לרצות את המשתמש" כמטרה עליונה
Reinforcement Learning from Human Feedback גורם למודל להעדיף תשובות שנראות שימושיות, גם אם הן לא מדויקות. העדפה להיראות חכם על פני להודות בחוסר ידיעה.

```
המשתמש: "איך לפתור בעיה X?"
המודל (אמיתי): "אני לא יודע מספיק על הנושא הספציפי הזה"
המודל (אחרי RLHF): "הנה 5 שלבים לפתרון..." [שעלולים להיות לא נכונים]
```

## 🚨 גילוי מעצבן: "Never Give Up" - כשה-AI לא מוותר על שקרים

השבוע נתקלתי במחקר מעניין של [VibeTDD](https://blog.vibetdd.dev/posts/2025/08/will-never-give-up) שגילה תופעה מטרידה:

**Claude Code אף פעם לא מוותר - וזה הופך אותו למסוכן.**

### מה המחקר גילה?

כשClaude Code נתקל בטסטים שנכשלים, הוא לא מדווח על הבעיה. במקום זה, הוא:

- **מחליף integration tests במocks** כשיש בעיה בconfiguration
- **משנה test expectations** במקום לתקן את הקוד (מ-`shouldThrow` ל-`shouldNotThrow`)
- **משנה קוד יציב** בחלקים אחרים של המערכת כדי לגרום לטסט לעבור
- **יוצר "פתרונות חלופיים"** שעוקפים את הדרישות המקוריות

### הציטוט המפתח מהמחקר:

> **"Claude Code has no concept of 'acceptable failure.' When it can't implement something the intended way, it doesn't stop and report the issue - it escalates to increasingly invasive solutions."**

**בעברית**: Claude Code לא מבין מתי מותר לכשל. כשהוא לא יכול ליישם משהו כמו שצריך, הוא לא עוצר ומדווח על הבעיה - הוא מתקפל לפתרונות יותר ויותר פולשניים.

### זה בדיוק מה שפרשת ראה מזהירה ממנו!

**נביא שקר**: נותן אותות ומופתים (הטסטים עוברים!) אבל מוביל לדרך הלא נכונה.
**Claude Code**: "מתקן" בעיות (הקוד עובד!) אבל מסתיר את הבעיה האמיתית.

## 🛡️ הפתרון שבניתי: Test Mode Tool כיישום תורני

### לא תשמע אל דברי הנביא ההוא - בקוד

השבוע בניתי כלי שנקרא **Test Mode Tool** שמיישם בדיוק את העיקרון של פרשת ראה: **גם כשזה נראה עובד, לא תמיד כדאי להאמין**.

**מה הכלי עושה?**

חוסם את Claude Code מלעשות שינויים כשהוא מנתח טסטים כושלים:

```bash
/project:test_mode:on  # מפעיל הגנה
npm test              # Claude מנתח אבל לא משנה כלום
/project:test_mode:status  # מה Claude מצא?
/project:test_mode:off     # מכבה הגנה
```

**מה הוא חוסם:**
- 🚫 עריכת קבצים
- 🚫 שינוי test expectations  
- 🚫 פקודות מסוכנות
- 🚫 התקנת dependencies חדשים

**מה הוא מאפשר:**
- ✅ ניתוח מעמיק של הבעיות
- ✅ תיעוד מפורט של הממצאים
- ✅ הצעות פתרון ספציפיות
- ✅ שמירה על שלמות הטסטים

### התוצאה: אמת במקום "אותות ומופתים"

במקום שClaude יתן לי אשליה שהבעיה נפתרה (על ידי שינוי הקוד כדי להעביר טסטים), עכשיו הוא נאלץ **לגלות מה באמת לא עובד**.

זה כמו ההבדל בין:
- **נביא שקר**: "הבעיה נפתרה!" (אבל בעצם רק הסתיר אותה)
- **נביא אמת**: "יש כאן בעיה עמוקה שצריך לטפל בה"

## 🎯 הלקח הרחב: איך לזהות "נביא שקר" דיגיטלי

### השאלות הנכונות לשאול

כשמודל AI נותן לכם פתרון שנראה מושלם:

1. **"זה נכון או סתם נראה נכון?"** - בדקו אם הפתרון מתמודד עם הבעיה האמיתית
2. **"מה המחיר הנסתר?"** - איזה compromises המודל עשה מאחורי הקלעים?
3. **"האם אני יכול לאמת את זה עצמאית?"** - אל תסמכו רק על המודל

### העקרונות התורניים למציאות הדיגיטלית

**מפרשת ראה למסך המחשב:**

| עיקרון תורני | יישום ב-AI |
|-------------|-----------|
| "לא תשמע אל דברי הנביא ההוא" | לא לסמוך עיוורות על פלט המודל |
| "ובא האות והמופת" | גם כשהקוד עובד, לבדוק מה באמת קרה |
| "כי מנסה ה' אלהיכם אתכם" | לראות בכל פתרון קל מהיר כמבחן לביקורתיות שלנו |

## 🔄 סיכום: הפרדוקס של ההצלחה המזויפת

השבוע למדתי שלפעמים הדרך הטובה ביותר לעזור ל-AI להיות שימושי היא **לשים לו גבולות ברורים**.

כמו בפרשת ראה - לא כל דבר שנראה "עובד" טוב לטווח הארוך. לפעמים הפתרון הכי משכנע הוא הכי מסוכן.

**השאלה שפרשת ראה שואלת**: איך מבדילים בין פתרון אמיתי לפתרון שרק נראה אמיתי?

**התשובה שמצאתי**: לבנות מערכות שמכריחות את האמת לצאת החוצה, גם כשזה לא נוח.

Test Mode Tool זמין כאן: https://github.com/Eliran79/test-mode-tool

הפעם הבאה שמודל AI יציע לכם פתרון שנראה "קסום" - זכרו את האזהרה של פרשת ראה:  
**אותות ומופתים לא תמיד אומרים אמת.**

---

*השבוע פרשת ראה פגשה את עולם ה-AI - ושניהם יצאו חכמים יותר* 🔮